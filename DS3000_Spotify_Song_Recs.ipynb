{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h2> DS 3000 - Fall 2019</h2> </center>\n",
    "<center> <h3> DS Report </h3> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1> Using User Activity to make Song Recommendations </h1> </center>\n",
    "<center><h4>Caterina Wang and Grace Brown</h4></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Executive Summary:\n",
    "\n",
    "In this project, we used a dataset containing a certain user's liked songs and disliked songs from playlists on their Spotify account. From there, we analyzed key features of this dataset in order to train our model to recognize songs this user would like, and dislike. After we trained our model, we then used it on another dataset of newly-released music in order to recommend the user new songs to listen to.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. <a href='#1'>INTRODUCTION</a>\n",
    "2. <a href='#2'>METHOD</a>\n",
    "3. <a href='#3'>RESULTS</a>\n",
    "4. <a href='#4'>DISCUSSION</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, orient your readers to your project. You've already written some of these in previous deliverables. Based on your final analysis, revise your problem statement and write a concise introduction section. This section should touch upon the following points, but should be written in full paragraphs. Your writing should incorporate all of these points (and more if you like) in a coherent way. Remember that you are trying to convince your readers that this is an important problem to tackle. \n",
    "\n",
    "Problem Statement\n",
    "* Describe the problem you would like to tackle. \n",
    "* What is the topic of your project? \n",
    "* What do you want to learn about it?\n",
    "\n",
    "The topic of our project is about creating new song recommendations for music listeners. It is important to tackle this problem in our project because there are many ways that users can look for new music, but it does take time for a music listener to look up different artists, and we want to alleviate the amount of time it takes for a music listener to find new music they enjoy. Therefore, we feel this way of recommending music can be run on any set of songs. We want to learn about how song recommendations are made, and if recommending songs based on song attributes of music a user likes is an accurate measure for song recommendation. \n",
    "\n",
    "Significance of the Problem\n",
    "* Why is it important to tackle this problem in your project?\n",
    "* In what ways could the insights from this project be useful?\n",
    "* Has there been previous work on your topic? Do some research into your topic. Cite your sources appropriately. You can use the numbered reference format or APA (if you are more comfortable with it).\n",
    "\n",
    "It is important to tackle this problem because all people have a personal connection with music, and their own music preferences. For music listeners looking for new songs they'll enjoy, it takes a good deal of research and looking artists up, which can take a pretty great deal of time. I think the insights from this project could be useful in looking at the way we recommend new music to people. After looking into how Spotify currently recommends users music specifically for their \"Discover Weekly\" playlist, there are 3 different ways they currently recommend music to users: Collaborative Filtering, NLP models, and Audio models. Collaborative Filtering is actually based off of other people's liked music and playlists, and they look at other people who enjoy similar music to you, and see if they are listening to anything that you are not listening to, and they recommend you those songs you have not yet listened to. NLP models actually analyze the words that people are using to describe artists in blog posts or articles all over the web. Spotify is constantly scraping the web, grouping different artists into similar categories based off of the adjectives used to describe their music. Lastly, Audio models actually analyze raw audio data to find similarities between different songs. They use neural networks to analyze key features of the raw audio, including time signature, key, mode, tempo, and loudness. Our approach is most similar to the third way they recommend music, as we are making our predictions based on the audio features of songs. They look at the raw audio data, however, wheras we are looking at the song features of each song provided by the API. With this approach, we are looking to explore new ways to recommend music and see the accuracy of the results they yield. \n",
    "\n",
    "Sources:\n",
    "Boam, Eric. “I Decoded the Spotify Recommendation Algorithm. Here's What I Found.” Medium, Medium, 18 Mar. 2019, medium.com/@ericboam/i-decoded-the-spotify-recommendation-algorithm-heres-what-i-found-4b0f3654035b.\n",
    "Ciocca, Sophia. “How Does Spotify Know You So Well?” Medium, Medium, 5 Apr. 2018, medium.com/s/story/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe.\n",
    "Pasick, Adam. “The Magic That Makes Spotify's Discover Weekly Playlists so Damn Good.” Quartz, Quartz, 25 June 2019, qz.com/571007/the-magic-that-makes-spotifys-discover-weekly-playlists-so-damn-good/.\n",
    "\n",
    "Questions/Hypothesis\n",
    "* End this section with a list of questions and hypotheses\n",
    "* You should tie these questions/hypotheses to the problem statement and its significance\n",
    "    * e.g. Given the aforementioned problem and its importance, we set out to tackle the following questions:\n",
    "\n",
    "Given the problem we are trying to solve, we do not have a hypothesis. However, we are looking into the answers of these questions:\n",
    "* Can we create effective song recommendation systems by analyzing a few key attributes of a user's liked songs?\n",
    "* Are the best song recommendations made from the audio model, or are they from one of the other two ways that song recommendations are created?\n",
    "* Which Machine Learning Algorithm will help us create the most accurate song recommendations?\n",
    "* Which song attributes have the greatest effect on the likeability of a song?\n",
    "\n",
    "    \n",
    "**Requirement:**\n",
    "* You should have at least one question tapping into the comparison of various machine learning algorithms in predicting your target variable from your features variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Data Acquisition\n",
    "\n",
    "* Describe where you obtained your data. Provide a link to the original source. \n",
    "* If you scraped your data, include your code as a script file.\n",
    "* Your data should be stored in an online repository (e.g., GitHub) and your code should retrieve your data from that online resource. You can read csv files from the Web in the same way that you read files from local drive.\n",
    "* Describe the dataset and variables. What do variables represent?\n",
    "\n",
    "For our dataset, at first we tried to scrape our data from the Spotify Web API, but it proved to be very difficult to extract the song features from our list of tracks, so we then created a dataset based off of the information on Caterina's Spotify account. We created two playlists, one of songs Caterina likes, and one of songs Caterina dislikes. Using http://static.echonest.com/SortYourMusic/ we were able to log into Caterina's Spotify account and obtain the song attributes for all songs in a certain playlist. These attributes included the Energy, BPM, which means Beats per Minute, Danceability, Loudness, Valence,  Acousticness, Length, Popularity, and RND, which means random. We ended up dropping the Length, Popularity, and Random columns as Length represents the length of a song, popularity represents how popular a song is based on how many users listen to the song, and random is just a random number assigned to a song so you can shuffle your playlist around. We felt that these 3 attributes did not help describe what the song actually sounds like at all, which we decided was the most important part of song likeability. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Variables\n",
    "* If you are testing hypotheses, what are your IVs and DVs?\n",
    "* For your predictive models, what are your features and target variables?\n",
    "\n",
    "For our predictive models, our features are the audio attributes of a given song, which are the different columns in our dataset. These include song Energy, Valence, Loudness, Danceability, Beats per Minute, and Acousticness. Our target variable is song likeability, and the only two possible values for this column are 0 or 1, with 0 representing the song is disliked by the user, and 1 representing the song is liked by the user.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Data Analysis\n",
    "* Specifically describe your predictive model. What outcome variable are you going to predict from what feature variables?\n",
    "* Describe whether this is a supervised or unsupervised learning problem. Also identify the sub-category of the learning task (e.g. classification).\n",
    "* What machine learning algorithms are you going to use? Why?\n",
    "\n",
    "Our predictive model is going to predict the target variable, which is song likeability, from the key features we determined during Feature Extraction: Energy, Loudness, and Valence. This is a form of supervised machine learning because we are using labeled data in order to classify our data, and then train our model to create predictions based on that data. In terms of Machine Learning Algorithms, we are going to compare 4 different classifiers against each other: Support Vector Machine, k-Nearest Neighbors, Decision Trees, and Random Forest. The first 3 we learned in class, and the last one, Random Forest is when you create a set of decision trees from a randomly selected subset of the training set, and each individual decision tree spits out a class prediction, and the class with the most votes becomes our class prediction. We decided to test these 4 different classifiers against each other because they all worked pretty well with our dataset, and then we also decided to add the Random Forest Classifier because one of the drawbacks of the Decision Tree Classifier was that you usually need an ensemble of trees for better generalization performance, which increase prediction accuracy, and that is exactly what the Random Forest Classifier does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Data Wrangling\n",
    "* Perform simple data cleaning (delete extra columns, deal with NA values, etc.)\n",
    "* Perform data wrangling to extract your features and target values (e.g., grouping your dataframe by columns, applying functions to format dataframes, etc.)\n",
    "* Preprocess your variables (e.g., scaling/transforming feature variables to normalize them)\n",
    "* Feature extraction (dummy variables, new features from existing features, etc.)\n",
    "* Use one feature selection technique to select a subset of your original features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Data Exploration\n",
    "* Generate appropriate data visualizations for your key variables identified in the previous section\n",
    "* You should have at least three visualizations (and at least two different visualization types)\n",
    "* For each visualization provide an explanation regarding the variables involved and an interpretation of the graph.\n",
    "* If you are using Plotly, insert your visualizations as images as well (upload the graph images to an online source, e.g. github, and link those in Jupyter Notebook)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Model Construction\n",
    "* If you proposed hypotheses, conduct your hypothesis tests\n",
    "* For your machine learning question(s), split data into training, validation, and testing sets (or use cross-validation)\n",
    "* Apply machine learning algorithms (apply at least three algorithms)\n",
    "* Train your algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Model Evaluation\n",
    "* Evaluate the performance of your algorithms on appropriate evaluation metrics, using your validation set\n",
    "* Interpret your results from multiple models (and hypothesis tests, if any)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Model Optimization\n",
    "* Tune your models using appropriate hyperparameters\n",
    "* Explain why you are doing this (e.g., to avoid overfitting, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Model Testing\n",
    "* Test your tuned algorithms using your testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DISCUSSION\n",
    "* Provide a summary of the steps you took to analyze your data and test your predictive model\n",
    "* Intepret your findings from 3.4., 3.5, and 3.6\n",
    "    * Which algorithms did you compare?\n",
    "    * Which algorithm(s) revealed best performance?\n",
    "    * Which algorithm(s) should be used for your predictive model?\n",
    "* If you tested hypotheses, interpret the results. What does it mean to have significant/non-significant differences with regards to your data?\n",
    "\n",
    "We compared 4 different machine learning classifiers: Support Vector Machine, k-Nearest Neighbors, Decision Trees, and Random Forest. The algorithm that revealed the best performance was the Support Vector Classifier, at 92% prediction accuracy, Random Forest also shows good performance, however the prediction accuracy fluctuates because each time it is run, a different set of Decision Trees is compared. However, the prediction accuracy stays between 84% and 96%. The prediction accuracy score represents the percentage of songs that were correctly guessed to be liked or disliked by the user, and it is run on the testing data after the model has been trained by the training data. The algorithm that we are using for our predictive model is the Support Vector Classifier because it showed the most consistenly highest prediction accuracy, at 92%. After this, we used Grid Search on the Support Vector Classifier in order to hyperparameter tune, and to find the optimal model architecture, and to avoid overfitting. Finally, after running Grid Search, we found that the most optimal parameters to use were C = 0.1, and gamma = 0.001, and kernel = \"linear\". Afterwards, we re-fit the SVC Model using those parameters, and received a prediction accuracy of 92% on the testing data. \n",
    "Furthermore, we inputted our New Music Data into our newly fitted model, and then filtered the songs in the New Music Dataframe by whether or not the model recommended the song to the user or not. This means that we filtered all of the songs for a target value of 1, meaning the model predicted that the user would like the song. This gave us 69 songs the model recommended to Caterina based off of the songs she liked and disliked. \n",
    "In the future, we could improve this project by obtaining more data. The dataset we had only contained 50 liked songs and 50 disliked songs, and not all songs were from different genres across the board. Having more data would of course give our model more information to learn from, but also having likes and dislikes from a wider variety of genres of music would allow the model to generalize better to any set of songs you give the model. Also, this project could benefit from using more sophisticated machine learning algorithms, such as neural networks. Since they are more complicated, this may yield more accurate results.\n",
    "\n",
    "\n",
    "* End this section with a conclusion paragraph containing some pointers for future work \n",
    "    *(e.g., get more data, perform another analysis, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTRIBUTIONS\n",
    "Since we were a group of 2, we did all of the project together, and would discuss every decision we made about the project together. Grace did more of the coding on her laptop, and Caterina did more of the research and written responses, but all aspects of the project have input from the both of us."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
